# Day 20: Project 2 - Character-Level RNN for Text Generation - Further Reading

This day synthesizes Phase 2 concepts into a comprehensive text generation project. Here are resources for best practices in building production-quality NLP systems.

## References

1. **Best Practices for Language Model Development**
   - [Hugging Face Course: NLP](https://huggingface.co/course/)
   - Comprehensive course covering data preprocessing, model training, evaluation, and deployment for NLP systems.

2. **The Fine-Tuning Handbook for Language Models**
   - [Fast.ai NLP Course](https://www.fast.ai/posts/2019-07-08-fastai-nlp.html)
   - Practical guide to transfer learning and fine-tuning language models from Jeremy Howard's fast.ai.

3. **Evaluating Text Generation Quality**
   - [ROUGE and METEOR Metrics](https://towardsdatascience.com/rouge-metric-how-and-when-to-use-it-9eba11192e57)
   - Guide to automatic evaluation metrics for text generation including ROUGE, METEOR, and BLEU scores.

4. **Decoding Strategies for Text Generation**
   - [Decoding Methods for NLP](https://huggingface.co/blog/how-to-generate)
   - Comprehensive guide to different decoding strategies (greedy, beam search, nucleus sampling) with implementations.

5. **Deploying NLP Models to Production**
   - [TorchServe: Serving PyTorch Models](https://pytorch.org/serve/)
   - Framework for deploying PyTorch NLP models to production with examples and best practices.

---

**Tip:** Start with reference #1 for comprehensive guidance, #4 for generation strategies, #3 for evaluation, and #5 for deployment considerations.
