# Day 27: Karpathy's minGPT - Understanding the Code - Further Reading

This day studies Andrej Karpathy's minGPT implementation, a minimal clean GPT codebase that demonstrates best practices in PyTorch and serves as an excellent educational resource.

## References

1. **minGPT GitHub Repository**
   - [Karpathy: minGPT](https://github.com/karpathy/mingpt)
   - Clean, minimal GPT implementation with excellent comments and examples for educational purposes.

2. **A Recipe for Training Neural Networks**
   - [Karpathy: Training Recipe](http://karpathy.github.io/2019/04/25/recipe/)
   - Best practices guide covering data pipeline, hyperparameter tuning, debugging, and training techniques.

3. **Building GPT from Scratch**
   - [Nano GPT Lecture](https://www.youtube.com/watch?v=kCc8FmEb1nY)
   - Video walkthrough of building a minimal GPT implementation from scratch with educational focus.

4. **PyTorch Best Practices**
   - [PyTorch: Tutorials and Examples](https://pytorch.org/tutorials/)
   - Official PyTorch tutorials demonstrating clean code patterns and best practices for research code.

5. **Understanding Model Initialization in Transformers**
   - [Proper Weight Initialization](https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-basics-to-kaiming-8d34c9c20285)
   - Deep dive into weight initialization strategies critical for training stable GPT models.

---

**Tip:** Start with reference #1 to read the code, #2 for training philosophy, #3 for video walkthrough, and #4-5 for implementation details.
