# Day 42: Building a Document Q&A System with RAG - Further Reading

This day covers implementing a practical question-answering system over custom documents using RAG, combining document retrieval with LLM prompting.

## References

1. **Building RAG Applications with LangChain**
   - [LangChain RAG Tutorial](https://langchain.com/docs/use_cases/question_answering/)
   - Complete guide to building Q&A systems with document loading and LLM chains.

2. **Vector Embeddings for Semantic Search**
   - [Sentence Transformers](https://www.sbert.net/)
   - Library for computing sentence embeddings and semantic similarity for document retrieval.

3. **Pinecone: Vector Database for RAG**
   - [Pinecone Documentation](https://docs.pinecone.io/)
   - Cloud vector database optimized for RAG applications at scale.

4. **Improving RAG with Reranking**
   - [Cross-Encoders for Semantic Search](https://www.sbert.net/docs/pretrained_cross-encoders/ce-ms-marco-mmarco-v2.html)
   - Using cross-encoders to rerank retrieval results for improved relevance.

5. **Evaluating Q&A Systems**
   - [SQUAD: 100,000+ Questions for Machine Reading](https://rajpurkar.github.io/SQuAD-explorer/)
   - Benchmark dataset and metrics for evaluating question-answering systems.

---

**Tip:** Start with reference #1 for implementation, #2 for embeddings, #3 for production deployment, and #4-5 for improving quality.
