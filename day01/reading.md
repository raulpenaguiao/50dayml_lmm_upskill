# Day 01: MNIST and MLPs - Further Reading

This day introduced fundamental concepts in machine learning: the MNIST dataset, neural networks, and model training. Here are some excellent publicly available resources to deepen your understanding.

## References

1. **MNIST Dataset Documentation**
   - [MNIST on Yann LeCun's Website](http://yann.lecun.com/exdb/mnist/)
   - The original source for the MNIST dataset with historical context, dataset details, and benchmark results from various algorithms.

2. **PyTorch Neural Networks Tutorial**
   - [PyTorch: Neural Networks](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)
   - Official PyTorch tutorial covering how to define, train, and evaluate neural networks with practical examples.

3. **Multi-Layer Perceptron (MLP) Explained**
   - [3Blue1Brown - Neural Networks Series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
   - Excellent visual explanations of how neural networks and MLPs work, with intuitive animations.

4. **Model Training and Optimization**
   - [Papers With Code - MNIST Benchmarks](https://paperswithcode.com/dataset/mnist)
   - Comprehensive collection of MNIST benchmark results and implementations, showing how different architectures and optimizers perform.

5. **PyTorch Model Saving and Loading**
   - [PyTorch: Saving and Loading Models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)
   - Official guide on how to save and load PyTorch models for reproducibility and deployment.

---

**Tip:** Start with reference #3 for intuitive understanding, then reference #1 for dataset details, and reference #2 for hands-on implementation guidance.
