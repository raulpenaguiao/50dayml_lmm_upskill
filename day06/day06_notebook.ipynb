{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6: Transfer Learning and Pretrained Models\n",
    "\n",
    "**Time:** 3-4 hours\n",
    "\n",
    "**Mathematical Prerequisites:**\n",
    "- Understanding of CNNs (from Day 2-3)\n",
    "- Feature representations and learned hierarchies\n",
    "- Optimization concepts (learning rates, gradient flow)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Today we explore **transfer learning**: using knowledge learned from one task (ImageNet classification) to solve another task (CIFAR-10 classification).\n",
    "\n",
    "Key concepts:\n",
    "1. Why transfer learning works (feature hierarchy)\n",
    "2. Feature extraction vs fine-tuning\n",
    "3. Working with pretrained models (ResNet, VGG, MobileNet)\n",
    "4. Layer freezing and selective fine-tuning\n",
    "5. Comparison of different strategies\n",
    "\n",
    "**Goal:** Achieve >85% accuracy on CIFAR-10 using transfer learning\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Theory - Why Transfer Learning Works\n",
    "\n",
    "### 1.1 Feature Hierarchy in CNNs\n",
    "\n",
    "CNNs learn hierarchical features:\n",
    "- **Early layers:** Low-level features (edges, textures, colors)\n",
    "- **Middle layers:** Mid-level features (patterns, shapes, object parts)\n",
    "- **Late layers:** High-level features (specific to the task)\n",
    "\n",
    "**Key Insight:** Early and middle layers learn **general** features that transfer well across tasks. Only the final layers are task-specific.\n",
    "\n",
    "### 1.2 Transfer Learning Strategies\n",
    "\n",
    "**1. Feature Extraction (Frozen Backbone)**\n",
    "- Freeze all pretrained layers\n",
    "- Only train the new classification head\n",
    "- Fast, requires less data\n",
    "- Use when: Small dataset, similar to ImageNet\n",
    "\n",
    "**2. Fine-Tuning (Unfrozen Layers)**\n",
    "- Unfreeze some/all pretrained layers\n",
    "- Train with small learning rate\n",
    "- Slower, requires more data\n",
    "- Use when: Moderate dataset, somewhat different from ImageNet\n",
    "\n",
    "**3. From Scratch**\n",
    "- Initialize randomly, train everything\n",
    "- Slowest, requires large dataset\n",
    "- Use when: Very large dataset, very different from ImageNet\n",
    "\n",
    "### 1.3 Learning Rate Strategy for Fine-Tuning\n",
    "\n",
    "When fine-tuning, use **discriminative learning rates**:\n",
    "- **Early layers:** Very small LR (e.g., 1e-5) - already learned good features\n",
    "- **Middle layers:** Medium LR (e.g., 1e-4)\n",
    "- **Final layers:** Larger LR (e.g., 1e-3) - need to adapt to new task\n",
    "\n",
    "This prevents catastrophic forgetting of pretrained features.\n",
    "\n",
    "### 1.4 ImageNet vs CIFAR-10\n",
    "\n",
    "**ImageNet:**\n",
    "- 1000 classes\n",
    "- 224Ã—224 images\n",
    "- 1.2M training images\n",
    "\n",
    "**CIFAR-10:**\n",
    "- 10 classes (airplane, car, bird, cat, deer, dog, frog, horse, ship, truck)\n",
    "- 32Ã—32 images (much smaller!)\n",
    "- 50K training images\n",
    "\n",
    "We'll need to handle the resolution difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Load CIFAR-10 Dataset\n",
    "\n",
    "CIFAR-10 contains 32Ã—32 color images in 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# For pretrained models, we need ImageNet normalization\n",
    "# ImageNet mean and std\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transforms for training (with augmentation)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize to ImageNet size\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# Transforms for testing (no augmentation)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize CIFAR-10 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original CIFAR-10 for visualization (without normalization)\n",
    "train_dataset_viz = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, \n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Visualize samples from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    # Find first sample of this class\n",
    "    for img, label in train_dataset_viz:\n",
    "        if label == i:\n",
    "            axes[i].imshow(img.permute(1, 2, 0))\n",
    "            axes[i].set_title(class_name)\n",
    "            axes[i].axis('off')\n",
    "            break\n",
    "\n",
    "plt.suptitle('CIFAR-10 Sample Images (32Ã—32)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show batch of images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(f\"\\nBatch shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"After preprocessing, images are: {images.shape[2]}Ã—{images.shape[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Strategy 1 - Feature Extraction (Frozen Backbone)\n",
    "\n",
    "We'll use ResNet18 pretrained on ImageNet and only train the final classification layer.\n",
    "\n",
    "### 3.1 Understanding ResNet18 Architecture\n",
    "\n",
    "ResNet18 structure:\n",
    "```\n",
    "Input (3Ã—224Ã—224)\n",
    "  â†“\n",
    "conv1 (7Ã—7, stride 2) â†’ 64Ã—112Ã—112\n",
    "  â†“\n",
    "maxpool â†’ 64Ã—56Ã—56\n",
    "  â†“\n",
    "layer1 (ResBlocks) â†’ 64Ã—56Ã—56\n",
    "  â†“\n",
    "layer2 (ResBlocks) â†’ 128Ã—28Ã—28\n",
    "  â†“\n",
    "layer3 (ResBlocks) â†’ 256Ã—14Ã—14\n",
    "  â†“\n",
    "layer4 (ResBlocks) â†’ 512Ã—7Ã—7\n",
    "  â†“\n",
    "avgpool â†’ 512Ã—1Ã—1\n",
    "  â†“\n",
    "fc â†’ 1000 classes (ImageNet)\n",
    "```\n",
    "\n",
    "We'll replace the final `fc` layer with our own for 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor():\n",
    "    \"\"\"Create ResNet18 with frozen backbone for feature extraction.\"\"\"\n",
    "    # Load pretrained ResNet18\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace final fully connected layer\n",
    "    # ResNet18 has 512 features before the fc layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)  # 10 classes for CIFAR-10\n",
    "    \n",
    "    return model, num_features\n",
    "\n",
    "# Create model\n",
    "feature_extractor, num_features = create_feature_extractor()\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "print(f\"Number of features before fc layer: {num_features}\")\n",
    "print(f\"\\nModel structure:\")\n",
    "print(feature_extractor)\n",
    "\n",
    "# Count trainable parameters\n",
    "total_params = sum(p.numel() for p in feature_extractor.parameters())\n",
    "trainable_params = sum(p.numel() for p in feature_extractor.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': running_loss / (pbar.n + 1),\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate on test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Evaluating'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_fe = optim.Adam(feature_extractor.fc.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "# Track metrics\n",
    "fe_train_losses = []\n",
    "fe_train_accs = []\n",
    "fe_test_losses = []\n",
    "fe_test_accs = []\n",
    "\n",
    "print(\"Training Feature Extractor (Frozen Backbone)...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        feature_extractor, train_loader, criterion, optimizer_fe, device\n",
    "    )\n",
    "    fe_train_losses.append(train_loss)\n",
    "    fe_train_accs.append(train_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc, _, _ = evaluate(\n",
    "        feature_extractor, test_loader, criterion, device\n",
    "    )\n",
    "    fe_test_losses.append(test_loss)\n",
    "    fe_test_accs.append(test_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "fe_time = time.time() - start_time\n",
    "print(f\"\\nFeature extraction training completed in {fe_time:.2f} seconds\")\n",
    "print(f\"Best test accuracy: {max(fe_test_accs):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Strategy 2 - Fine-Tuning\n",
    "\n",
    "Now we'll unfreeze some layers and fine-tune with a smaller learning rate.\n",
    "\n",
    "### 4.1 Selective Layer Unfreezing\n",
    "\n",
    "We'll unfreeze the last ResNet block (layer4) and the fc layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuned_model():\n",
    "    \"\"\"Create ResNet18 with selective unfreezing for fine-tuning.\"\"\"\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze layer4 (last ResNet block)\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Replace and unfreeze fc layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "finetuned_model = create_finetuned_model()\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in finetuned_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in finetuned_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
    "\n",
    "# Show which layers are trainable\n",
    "print(\"\\nTrainable layers:\")\n",
    "for name, param in finetuned_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  {name}: {param.numel():,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Discriminative Learning Rates\n",
    "\n",
    "We'll use different learning rates for different parts of the network:\n",
    "- layer4: 1e-4 (smaller LR for pretrained features)\n",
    "- fc: 1e-3 (larger LR for new classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer with different learning rates per layer group\n",
    "optimizer_ft = optim.Adam([\n",
    "    {'params': finetuned_model.layer4.parameters(), 'lr': 1e-4},\n",
    "    {'params': finetuned_model.fc.parameters(), 'lr': 1e-3}\n",
    "])\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_ft = optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
    "\n",
    "print(\"Optimizer configuration:\")\n",
    "for i, param_group in enumerate(optimizer_ft.param_groups):\n",
    "    print(f\"  Group {i}: LR = {param_group['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track metrics\n",
    "ft_train_losses = []\n",
    "ft_train_accs = []\n",
    "ft_test_losses = []\n",
    "ft_test_accs = []\n",
    "\n",
    "print(\"Training Fine-Tuned Model...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        finetuned_model, train_loader, criterion, optimizer_ft, device\n",
    "    )\n",
    "    ft_train_losses.append(train_loss)\n",
    "    ft_train_accs.append(train_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc, _, _ = evaluate(\n",
    "        finetuned_model, test_loader, criterion, device\n",
    "    )\n",
    "    ft_test_losses.append(test_loss)\n",
    "    ft_test_accs.append(test_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler_ft.step()\n",
    "    print(f\"Learning rates: {[group['lr'] for group in optimizer_ft.param_groups]}\")\n",
    "\n",
    "ft_time = time.time() - start_time\n",
    "print(f\"\\nFine-tuning completed in {ft_time:.2f} seconds\")\n",
    "print(f\"Best test accuracy: {max(ft_test_accs):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Strategy 3 - Training from Scratch\n",
    "\n",
    "For comparison, let's train ResNet18 from scratch (random initialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model from scratch (no pretrained weights)\n",
    "scratch_model = models.resnet18(pretrained=False)\n",
    "scratch_model.fc = nn.Linear(scratch_model.fc.in_features, 10)\n",
    "scratch_model = scratch_model.to(device)\n",
    "\n",
    "# All parameters are trainable\n",
    "trainable_params = sum(p.numel() for p in scratch_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Optimizer with higher learning rate (no pretrained weights to preserve)\n",
    "optimizer_scratch = optim.Adam(scratch_model.parameters(), lr=0.001)\n",
    "scheduler_scratch = optim.lr_scheduler.StepLR(optimizer_scratch, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track metrics\n",
    "scratch_train_losses = []\n",
    "scratch_train_accs = []\n",
    "scratch_test_losses = []\n",
    "scratch_test_accs = []\n",
    "\n",
    "print(\"Training from Scratch...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        scratch_model, train_loader, criterion, optimizer_scratch, device\n",
    "    )\n",
    "    scratch_train_losses.append(train_loss)\n",
    "    scratch_train_accs.append(train_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc, _, _ = evaluate(\n",
    "        scratch_model, test_loader, criterion, device\n",
    "    )\n",
    "    scratch_test_losses.append(test_loss)\n",
    "    scratch_test_accs.append(test_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    scheduler_scratch.step()\n",
    "\n",
    "scratch_time = time.time() - start_time\n",
    "print(f\"\\nTraining from scratch completed in {scratch_time:.2f} seconds\")\n",
    "print(f\"Best test accuracy: {max(scratch_test_accs):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Compare Different Architectures\n",
    "\n",
    "Let's try different pretrained architectures: VGG16 and MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pretrained_model(model_name, num_epochs=10):\n",
    "    \"\"\"Train a pretrained model with feature extraction.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    if model_name == 'VGG16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        num_features = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_features, 10)\n",
    "        # Freeze all except classifier\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    elif model_name == 'MobileNetV2':\n",
    "        model = models.mobilenet_v2(pretrained=True)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_features, 10)\n",
    "        # Freeze all except classifier\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\\n\")\n",
    "    \n",
    "    # Setup training\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "    \n",
    "    # Track metrics\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        _, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Evaluate\n",
    "        _, test_acc, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f\"Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%\\n\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_accs': train_accs,\n",
    "        'test_accs': test_accs,\n",
    "        'best_acc': max(test_accs),\n",
    "        'time': training_time,\n",
    "        'total_params': total_params,\n",
    "        'trainable_params': trainable_params\n",
    "    }\n",
    "\n",
    "# Train VGG16\n",
    "vgg_results = train_pretrained_model('VGG16', num_epochs=5)\n",
    "\n",
    "# Train MobileNetV2\n",
    "mobilenet_results = train_pretrained_model('MobileNetV2', num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Comprehensive Comparison and Analysis\n",
    "\n",
    "### 7.1 Training Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Training accuracy\n",
    "axes[0, 0].plot(fe_train_accs, label='Feature Extraction', marker='o')\n",
    "axes[0, 0].plot(ft_train_accs, label='Fine-Tuning', marker='s')\n",
    "axes[0, 0].plot(scratch_train_accs, label='From Scratch', marker='^')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy (%)')\n",
    "axes[0, 0].set_title('Training Accuracy Comparison (ResNet18)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test accuracy\n",
    "axes[0, 1].plot(fe_test_accs, label='Feature Extraction', marker='o')\n",
    "axes[0, 1].plot(ft_test_accs, label='Fine-Tuning', marker='s')\n",
    "axes[0, 1].plot(scratch_test_accs, label='From Scratch', marker='^')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Test Accuracy Comparison (ResNet18)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Training loss\n",
    "axes[1, 0].plot(fe_train_losses, label='Feature Extraction', marker='o')\n",
    "axes[1, 0].plot(ft_train_losses, label='Fine-Tuning', marker='s')\n",
    "axes[1, 0].plot(scratch_train_losses, label='From Scratch', marker='^')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].set_title('Training Loss Comparison (ResNet18)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test loss\n",
    "axes[1, 1].plot(fe_test_losses, label='Feature Extraction', marker='o')\n",
    "axes[1, 1].plot(ft_test_losses, label='Fine-Tuning', marker='s')\n",
    "axes[1, 1].plot(scratch_test_losses, label='From Scratch', marker='^')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].set_title('Test Loss Comparison (ResNet18)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Architecture Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different architectures\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Test accuracy over epochs\n",
    "ax1.plot(fe_test_accs, label='ResNet18', marker='o')\n",
    "ax1.plot(vgg_results['test_accs'], label='VGG16', marker='s')\n",
    "ax1.plot(mobilenet_results['test_accs'], label='MobileNetV2', marker='^')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Test Accuracy (%)')\n",
    "ax1.set_title('Architecture Comparison (Feature Extraction)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Bar chart of best accuracies\n",
    "architectures = ['ResNet18', 'VGG16', 'MobileNetV2']\n",
    "best_accs = [max(fe_test_accs), vgg_results['best_acc'], mobilenet_results['best_acc']]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "bars = ax2.bar(architectures, best_accs, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('Best Test Accuracy (%)')\n",
    "ax2.set_title('Best Test Accuracy by Architecture')\n",
    "ax2.set_ylim([min(best_accs) - 5, 100])\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, best_accs):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary dataframe\n",
    "summary_data = [\n",
    "    {\n",
    "        'Strategy': 'Feature Extraction',\n",
    "        'Architecture': 'ResNet18',\n",
    "        'Best Test Acc (%)': max(fe_test_accs),\n",
    "        'Training Time (s)': fe_time,\n",
    "        'Trainable Params': sum(p.numel() for p in feature_extractor.parameters() if p.requires_grad),\n",
    "        'Total Params': sum(p.numel() for p in feature_extractor.parameters())\n",
    "    },\n",
    "    {\n",
    "        'Strategy': 'Fine-Tuning',\n",
    "        'Architecture': 'ResNet18',\n",
    "        'Best Test Acc (%)': max(ft_test_accs),\n",
    "        'Training Time (s)': ft_time,\n",
    "        'Trainable Params': sum(p.numel() for p in finetuned_model.parameters() if p.requires_grad),\n",
    "        'Total Params': sum(p.numel() for p in finetuned_model.parameters())\n",
    "    },\n",
    "    {\n",
    "        'Strategy': 'From Scratch',\n",
    "        'Architecture': 'ResNet18',\n",
    "        'Best Test Acc (%)': max(scratch_test_accs),\n",
    "        'Training Time (s)': scratch_time,\n",
    "        'Trainable Params': sum(p.numel() for p in scratch_model.parameters() if p.requires_grad),\n",
    "        'Total Params': sum(p.numel() for p in scratch_model.parameters())\n",
    "    },\n",
    "    {\n",
    "        'Strategy': 'Feature Extraction',\n",
    "        'Architecture': 'VGG16',\n",
    "        'Best Test Acc (%)': vgg_results['best_acc'],\n",
    "        'Training Time (s)': vgg_results['time'],\n",
    "        'Trainable Params': vgg_results['trainable_params'],\n",
    "        'Total Params': vgg_results['total_params']\n",
    "    },\n",
    "    {\n",
    "        'Strategy': 'Feature Extraction',\n",
    "        'Architecture': 'MobileNetV2',\n",
    "        'Best Test Acc (%)': mobilenet_results['best_acc'],\n",
    "        'Training Time (s)': mobilenet_results['time'],\n",
    "        'Trainable Params': mobilenet_results['trainable_params'],\n",
    "        'Total Params': mobilenet_results['total_params']\n",
    "    }\n",
    "]\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "df_summary['Param Ratio (%)'] = 100 * df_summary['Trainable Params'] / df_summary['Total Params']\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE COMPARISON SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Key insights\n",
    "print(\"\\nKEY INSIGHTS:\")\n",
    "print(f\"1. Best overall accuracy: {df_summary['Best Test Acc (%)'].max():.2f}% \"\n",
    "      f\"({df_summary.loc[df_summary['Best Test Acc (%)'].idxmax(), 'Strategy']} - \"\n",
    "      f\"{df_summary.loc[df_summary['Best Test Acc (%)'].idxmax(), 'Architecture']})\")\n",
    "print(f\"2. Fastest training: {df_summary['Training Time (s)'].min():.2f}s \"\n",
    "      f\"({df_summary.loc[df_summary['Training Time (s)'].idxmin(), 'Strategy']} - \"\n",
    "      f\"{df_summary.loc[df_summary['Training Time (s)'].idxmin(), 'Architecture']})\")\n",
    "print(f\"3. Most parameter efficient: {df_summary['Param Ratio (%)'].min():.2f}% trainable \"\n",
    "      f\"({df_summary.loc[df_summary['Param Ratio (%)'].idxmin(), 'Architecture']})\")\n",
    "print(f\"4. Transfer learning benefit: +{max(fe_test_accs) - max(scratch_test_accs):.2f}% over training from scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Detailed Evaluation of Best Model\n",
    "\n",
    "Let's do a comprehensive evaluation of the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model (fine-tuned ResNet18)\n",
    "best_model = finetuned_model\n",
    "print(\"Evaluating Fine-Tuned ResNet18 (Best Model)\\n\")\n",
    "\n",
    "# Get predictions\n",
    "_, test_acc, predictions, true_labels = evaluate(best_model, test_loader, criterion, device)\n",
    "print(f\"Final Test Accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - Fine-Tuned ResNet18 on CIFAR-10', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Per-Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(true_labels, predictions, target_names=classes))\n",
    "\n",
    "# Per-class accuracy\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "# Visualize per-class accuracy\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "bars = ax1.bar(classes, per_class_acc * 100, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Per-Class Accuracy', fontsize=14)\n",
    "ax1.set_ylim([0, 100])\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.axhline(y=test_acc, color='red', linestyle='--', label=f'Overall: {test_acc:.2f}%')\n",
    "ax1.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, per_class_acc * 100):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Sorted by accuracy\n",
    "sorted_indices = np.argsort(per_class_acc)\n",
    "sorted_classes = [classes[i] for i in sorted_indices]\n",
    "sorted_accs = per_class_acc[sorted_indices] * 100\n",
    "\n",
    "bars2 = ax2.barh(sorted_classes, sorted_accs, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "ax2.set_xlabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Per-Class Accuracy (Sorted)', fontsize=14)\n",
    "ax2.set_xlim([0, 100])\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "ax2.axvline(x=test_acc, color='red', linestyle='--', label=f'Overall: {test_acc:.2f}%')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print hardest and easiest classes\n",
    "print(f\"\\nEasiest class: {classes[per_class_acc.argmax()]} ({per_class_acc.max()*100:.2f}%)\")\n",
    "print(f\"Hardest class: {classes[per_class_acc.argmin()]} ({per_class_acc.min()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Misclassification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common misclassifications\n",
    "cm_no_diag = cm.copy()\n",
    "np.fill_diagonal(cm_no_diag, 0)\n",
    "\n",
    "# Top 5 misclassifications\n",
    "print(\"Top 5 Most Common Misclassifications:\\n\")\n",
    "flat_indices = np.argsort(cm_no_diag.ravel())[::-1]\n",
    "for i, flat_idx in enumerate(flat_indices[:5]):\n",
    "    true_idx, pred_idx = np.unravel_index(flat_idx, cm.shape)\n",
    "    count = cm_no_diag[true_idx, pred_idx]\n",
    "    print(f\"{i+1}. {classes[true_idx]:>12} â†’ {classes[pred_idx]:>12}: {count:4d} errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Visualize Correct and Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some test images without normalization for visualization\n",
    "test_dataset_viz = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, \n",
    "    transform=transforms.Compose([transforms.Resize(224), transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Find examples of correct and incorrect predictions\n",
    "correct_indices = np.where(predictions == true_labels)[0]\n",
    "incorrect_indices = np.where(predictions != true_labels)[0]\n",
    "\n",
    "# Visualize correct predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('Correct Predictions', fontsize=14, y=1.02)\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    idx = correct_indices[i]\n",
    "    img, _ = test_dataset_viz[idx]\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    ax.set_title(f'Predicted: {classes[predictions[idx]]}\\nTrue: {classes[true_labels[idx]]}', \n",
    "                 fontsize=10, color='green')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize incorrect predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('Incorrect Predictions', fontsize=14, y=1.02)\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    idx = incorrect_indices[i]\n",
    "    img, _ = test_dataset_viz[idx]\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    ax.set_title(f'Predicted: {classes[predictions[idx]]}\\nTrue: {classes[true_labels[idx]]}', \n",
    "                 fontsize=10, color='red')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Key Takeaways and Best Practices\n",
    "\n",
    "### 9.1 When to Use Each Strategy\n",
    "\n",
    "**Feature Extraction (Frozen Backbone):**\n",
    "- âœ… Use when: Small dataset, similar to ImageNet\n",
    "- âœ… Advantages: Fast training, less data required, no overfitting\n",
    "- âŒ Disadvantages: May not adapt well to very different domains\n",
    "- ðŸ“Š Our result: ~{max(fe_test_accs):.1f}% accuracy\n",
    "\n",
    "**Fine-Tuning:**\n",
    "- âœ… Use when: Medium dataset, somewhat different from ImageNet\n",
    "- âœ… Advantages: Better accuracy, adapts to new domain\n",
    "- âŒ Disadvantages: Slower, requires careful learning rate tuning\n",
    "- ðŸ“Š Our result: ~{max(ft_test_accs):.1f}% accuracy\n",
    "\n",
    "**Training from Scratch:**\n",
    "- âœ… Use when: Very large dataset, very different from ImageNet\n",
    "- âœ… Advantages: Complete control, no domain mismatch\n",
    "- âŒ Disadvantages: Requires massive data, slow convergence\n",
    "- ðŸ“Š Our result: ~{max(scratch_test_accs):.1f}% accuracy\n",
    "\n",
    "### 9.2 Best Practices\n",
    "\n",
    "1. **Always start with transfer learning** unless you have >1M samples\n",
    "2. **Use discriminative learning rates** when fine-tuning\n",
    "3. **Match preprocessing** to pretrained model (ImageNet normalization)\n",
    "4. **Freeze batch norm layers** when fine-tuning on small batches\n",
    "5. **Try multiple architectures** - different models excel at different tasks\n",
    "6. **Progressive unfreezing** - unfreeze layers gradually if needed\n",
    "\n",
    "### 9.3 Architecture Selection Guidelines\n",
    "\n",
    "**ResNet:**\n",
    "- Good all-around choice\n",
    "- Skip connections help with gradient flow\n",
    "- Multiple sizes available (18, 34, 50, 101, 152)\n",
    "\n",
    "**VGG:**\n",
    "- Simple architecture, easy to understand\n",
    "- Large model size, slower training\n",
    "- Good for feature extraction\n",
    "\n",
    "**MobileNet:**\n",
    "- Designed for mobile/edge devices\n",
    "- Much smaller, faster\n",
    "- Slight accuracy trade-off\n",
    "- Great for deployment\n",
    "\n",
    "### 9.4 Mathematical Insight: Why Transfer Learning Works\n",
    "\n",
    "From an optimization perspective, pretrained weights provide a good initialization:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_{\\theta} L(\\theta; D_{\\text{target}})\n",
    "$$\n",
    "\n",
    "Starting from $\\theta_{\\text{pretrained}}$ (learned on ImageNet) is much closer to $\\theta^*$ than random initialization, especially for early layers that learn universal features.\n",
    "\n",
    "This reduces the optimization path length and prevents overfitting on small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: (Optional) Advanced Topics\n",
    "\n",
    "### Progressive Unfreezing\n",
    "\n",
    "For very different domains, try progressive unfreezing:\n",
    "1. Train only fc layer for N epochs\n",
    "2. Unfreeze layer4, train for N epochs\n",
    "3. Unfreeze layer3, train for N epochs\n",
    "4. Continue as needed\n",
    "\n",
    "This prevents catastrophic forgetting.\n",
    "\n",
    "### Domain-Specific Augmentation\n",
    "\n",
    "CIFAR-10 benefits from:\n",
    "- Horizontal flips (makes sense for natural images)\n",
    "- Random crops\n",
    "- Color jittering\n",
    "\n",
    "But NOT:\n",
    "- Vertical flips (airplanes don't fly upside down)\n",
    "- Large rotations (cars aren't rotated 90Â°)\n",
    "\n",
    "Always consider domain knowledge when choosing augmentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've mastered transfer learning and pretrained models. You now understand:\n",
    "\n",
    "âœ… Why transfer learning works (feature hierarchy)  \n",
    "âœ… Feature extraction vs fine-tuning strategies  \n",
    "âœ… Working with multiple architectures (ResNet, VGG, MobileNet)  \n",
    "âœ… Discriminative learning rates and layer freezing  \n",
    "âœ… When to use each strategy  \n",
    "âœ… Comprehensive model evaluation  \n",
    "\n",
    "**Achievement:** >85% accuracy on CIFAR-10 using transfer learning!\n",
    "\n",
    "**Key Result:** Transfer learning provided +{max(fe_test_accs) - max(scratch_test_accs):.1f}% improvement over training from scratch\n",
    "\n",
    "**Time spent:** ~3-4 hours\n",
    "\n",
    "**Next:** Day 7 - Model Evaluation and Metrics (comprehensive evaluation beyond accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
