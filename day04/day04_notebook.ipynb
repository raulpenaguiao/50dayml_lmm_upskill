{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Day 04: Advanced Optimization and Gradient Dynamics\n",
    "\n",
    "**Goal:** Master modern optimization algorithms and understand gradient flow in deep networks.\n",
    "\n",
    "**Prerequisites:** You understand gradient descent, the chain rule, and basic optimization theory. This focuses on practical deep learning challenges.\n",
    "\n",
    "**Time estimate:** 3-4 hours\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll explore:\n",
    "1. **Mathematical foundations** of modern optimizers\n",
    "2. **Implement from scratch**: SGD+Momentum, Nesterov, RMSprop, Adam\n",
    "3. **Convergence analysis** and learning rate sensitivity\n",
    "4. **Gradient flow** in deep networks\n",
    "5. **Numerical stability** considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory",
   "metadata": {},
   "source": [
    "## Mathematical Foundations\n",
    "\n",
    "### 1. Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Basic update rule:\n",
    "$$\\theta_{t+1} = \\theta_t - \\alpha \\nabla L(\\theta_t)$$\n",
    "\n",
    "**Issues:**\n",
    "- High variance in gradient estimates\n",
    "- Poor conditioning (different scales in different dimensions)\n",
    "- Oscillation in ravines\n",
    "\n",
    "---\n",
    "\n",
    "### 2. SGD with Momentum (Polyak, 1964)\n",
    "\n",
    "Introduces velocity to smooth updates:\n",
    "\n",
    "$$v_{t+1} = \\beta v_t + \\nabla L(\\theta_t)$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\alpha v_{t+1}$$\n",
    "\n",
    "**Interpretation:**\n",
    "- Exponentially weighted moving average of gradients\n",
    "- $\\beta \\in [0, 1)$ controls momentum (typically 0.9)\n",
    "- Accelerates in consistent directions\n",
    "- Dampens oscillations\n",
    "\n",
    "**Mathematical insight:** With $\\beta = 0.9$, we average approximately $\\frac{1}{1-\\beta} = 10$ past gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Nesterov Accelerated Gradient (NAG)\n",
    "\n",
    "\"Look-ahead\" gradient:\n",
    "\n",
    "$$v_{t+1} = \\beta v_t + \\nabla L(\\theta_t - \\alpha \\beta v_t)$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\alpha v_{t+1}$$\n",
    "\n",
    "**Key difference:** Evaluate gradient at the \"look-ahead\" position $\\theta_t - \\alpha \\beta v_t$\n",
    "\n",
    "**Advantage:** Better convergence rate in convex settings ($O(1/t^2)$ vs $O(1/t)$ for momentum)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. RMSprop (Hinton, 2012)\n",
    "\n",
    "Adaptive learning rates per parameter:\n",
    "\n",
    "$$v_{t+1} = \\beta v_t + (1-\\beta)(\\nabla L(\\theta_t))^2$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{v_{t+1} + \\epsilon}} \\nabla L(\\theta_t)$$\n",
    "\n",
    "**Interpretation:**\n",
    "- Divide learning rate by (running average of) gradient magnitude\n",
    "- Large gradients → smaller effective learning rate\n",
    "- Small gradients → larger effective learning rate\n",
    "- Connection to **diagonal preconditioning**: $D^{-1/2}$ where $D = \\text{diag}(v_t)$\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Adam (Kingma & Ba, 2015)\n",
    "\n",
    "Combines momentum + RMSprop:\n",
    "\n",
    "$$m_{t+1} = \\beta_1 m_t + (1-\\beta_1)\\nabla L(\\theta_t) \\quad \\text{(first moment)}$$\n",
    "$$v_{t+1} = \\beta_2 v_t + (1-\\beta_2)(\\nabla L(\\theta_t))^2 \\quad \\text{(second moment)}$$\n",
    "\n",
    "**Bias correction** (important for early iterations):\n",
    "$$\\hat{m}_{t+1} = \\frac{m_{t+1}}{1-\\beta_1^{t+1}}, \\quad \\hat{v}_{t+1} = \\frac{v_{t+1}}{1-\\beta_2^{t+1}}$$\n",
    "\n",
    "**Update:**\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v}_{t+1}} + \\epsilon} \\hat{m}_{t+1}$$\n",
    "\n",
    "**Typical hyperparameters:** $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\epsilon = 10^{-8}$\n",
    "\n",
    "**Why it works:**\n",
    "- Adapts learning rates per parameter\n",
    "- Momentum helps with sparse gradients\n",
    "- Bias correction prevents initial underestimation\n",
    "- Effective step size roughly bounded by $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. Implementing Optimizers from Scratch\n",
    "\n",
    "We'll implement all major optimizers to understand their mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-optimizers",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum:\n",
    "    \"\"\"\n",
    "    SGD with Momentum (Polyak)\n",
    "    \n",
    "    Update rules:\n",
    "        v_t = beta * v_{t-1} + grad\n",
    "        theta_t = theta_{t-1} - lr * v_t\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=0.01, momentum=0.9):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.velocity = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                # v_t = beta * v_{t-1} + grad\n",
    "                self.velocity[i].mul_(self.momentum).add_(p.grad)\n",
    "                \n",
    "                # theta_t = theta_{t-1} - lr * v_t\n",
    "                p.data.add_(self.velocity[i], alpha=-self.lr)\n",
    "\n",
    "\n",
    "class NesterovMomentum:\n",
    "    \"\"\"\n",
    "    Nesterov Accelerated Gradient\n",
    "    \n",
    "    Look-ahead gradient evaluation\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=0.01, momentum=0.9):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.velocity = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                # Nesterov momentum\n",
    "                v_prev = self.velocity[i].clone()\n",
    "                self.velocity[i].mul_(self.momentum).add_(p.grad)\n",
    "                \n",
    "                # Update with look-ahead term\n",
    "                p.data.add_(self.velocity[i], alpha=-self.lr)\n",
    "                p.data.add_(v_prev, alpha=-self.lr * self.momentum)\n",
    "\n",
    "\n",
    "class RMSpropOptimizer:\n",
    "    \"\"\"\n",
    "    RMSprop: Root Mean Square Propagation\n",
    "    \n",
    "    Adaptive learning rates based on recent gradient magnitudes\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=0.01, beta=0.9, eps=1e-8):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.eps = eps\n",
    "        self.v = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                # v_t = beta * v_{t-1} + (1-beta) * grad^2\n",
    "                self.v[i].mul_(self.beta).addcmul_(p.grad, p.grad, value=1-self.beta)\n",
    "                \n",
    "                # theta_t = theta_{t-1} - lr / sqrt(v_t + eps) * grad\n",
    "                p.data.addcdiv_(p.grad, self.v[i].sqrt().add_(self.eps), value=-self.lr)\n",
    "\n",
    "\n",
    "class AdamOptimizer:\n",
    "    \"\"\"\n",
    "    Adam: Adaptive Moment Estimation\n",
    "    \n",
    "    Combines momentum (first moment) and RMSprop (second moment)\n",
    "    with bias correction\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        \n",
    "        # First moment (momentum)\n",
    "        self.m = [torch.zeros_like(p.data) for p in self.params]\n",
    "        # Second moment (RMSprop)\n",
    "        self.v = [torch.zeros_like(p.data) for p in self.params]\n",
    "        \n",
    "        self.t = 0  # Timestep for bias correction\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "    \n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, p in enumerate(self.params):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                # First moment: m_t = beta1 * m_{t-1} + (1-beta1) * grad\n",
    "                self.m[i].mul_(self.beta1).add_(p.grad, alpha=1-self.beta1)\n",
    "                \n",
    "                # Second moment: v_t = beta2 * v_{t-1} + (1-beta2) * grad^2\n",
    "                self.v[i].mul_(self.beta2).addcmul_(p.grad, p.grad, value=1-self.beta2)\n",
    "                \n",
    "                # Bias correction\n",
    "                m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "                v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "                \n",
    "                # Update: theta_t = theta_{t-1} - lr * m_hat / (sqrt(v_hat) + eps)\n",
    "                p.data.addcdiv_(m_hat, v_hat.sqrt().add_(self.eps), value=-self.lr)\n",
    "\n",
    "\n",
    "print(\"Custom optimizers implemented:\")\n",
    "print(\"  - SGDMomentum\")\n",
    "print(\"  - NesterovMomentum\")\n",
    "print(\"  - RMSpropOptimizer\")\n",
    "print(\"  - AdamOptimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## 2. Setup: Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "# Simple MLP for experiments\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=128, num_classes=10):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "print(\"\\nModel architecture:\")\n",
    "model = SimpleMLP().to(device)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## 3. Training Function with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_optimizer(model, optimizer, num_epochs=5, verbose=True):\n",
    "    \"\"\"\n",
    "    Train model and track detailed metrics\n",
    "    \n",
    "    Returns:\n",
    "        history: dict with losses, accuracies, gradient norms\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_acc': [],\n",
    "        'grad_norms': [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        epoch_grad_norms = []\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Compute gradient norm\n",
    "            total_norm = 0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** 0.5\n",
    "            epoch_grad_norms.append(total_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Testing\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                test_total += target.size(0)\n",
    "        \n",
    "        test_acc = 100. * test_correct / test_total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['grad_norms'].append(np.mean(epoch_grad_norms))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}: '\n",
    "                  f'Loss={train_loss:.4f}, '\n",
    "                  f'Train Acc={train_acc:.2f}%, '\n",
    "                  f'Test Acc={test_acc:.2f}%, '\n",
    "                  f'Grad Norm={history[\"grad_norms\"][-1]:.4f}')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 4. Optimizer Comparison Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-optimizers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers to compare\n",
    "lr = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "optimizers_config = [\n",
    "    ('SGD (no momentum)', lambda p: torch.optim.SGD(p, lr=lr)),\n",
    "    ('SGD + Momentum', lambda p: SGDMomentum(p, lr=lr, momentum=0.9)),\n",
    "    ('Nesterov', lambda p: NesterovMomentum(p, lr=lr, momentum=0.9)),\n",
    "    ('RMSprop', lambda p: RMSpropOptimizer(p, lr=lr)),\n",
    "    ('Adam', lambda p: AdamOptimizer(p, lr=lr)),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, opt_fn in optimizers_config:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training with {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Fresh model for each optimizer\n",
    "    model = SimpleMLP().to(device)\n",
    "    optimizer = opt_fn(model.parameters())\n",
    "    \n",
    "    history = train_with_optimizer(model, optimizer, num_epochs=num_epochs)\n",
    "    results[name] = history\n",
    "    \n",
    "    print(f\"Final test accuracy: {history['test_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comprehensive comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "epochs = range(1, num_epochs + 1)\n",
    "colors = ['b', 'g', 'r', 'c', 'm']\n",
    "markers = ['o', 's', '^', 'D', 'v']\n",
    "\n",
    "# Training loss\n",
    "for (name, history), color, marker in zip(results.items(), colors, markers):\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], \n",
    "                    label=name, color=color, marker=marker, linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Training Loss', fontsize=12)\n",
    "axes[0, 0].set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test accuracy\n",
    "for (name, history), color, marker in zip(results.items(), colors, markers):\n",
    "    axes[0, 1].plot(epochs, history['test_acc'],\n",
    "                    label=name, color=color, marker=marker, linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "axes[0, 1].set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Gradient norms\n",
    "for (name, history), color, marker in zip(results.items(), colors, markers):\n",
    "    axes[1, 0].plot(epochs, history['grad_norms'],\n",
    "                    label=name, color=color, marker=marker, linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Gradient Norm', fontsize=12)\n",
    "axes[1, 0].set_title('Gradient Norm Evolution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Final accuracy bar chart\n",
    "names = list(results.keys())\n",
    "final_accs = [results[name]['test_acc'][-1] for name in names]\n",
    "bars = axes[1, 1].bar(range(len(names)), final_accs, color=colors)\n",
    "axes[1, 1].set_xticks(range(len(names)))\n",
    "axes[1, 1].set_xticklabels(names, rotation=45, ha='right')\n",
    "axes[1, 1].set_ylabel('Final Test Accuracy (%)', fontsize=12)\n",
    "axes[1, 1].set_title('Final Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, final_accs):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: Final Test Accuracies\")\n",
    "print(\"=\"*70)\n",
    "for name in names:\n",
    "    final_acc = results[name]['test_acc'][-1]\n",
    "    print(f\"{name:20s}: {final_acc:6.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## 5. Learning Rate Sensitivity Analysis\n",
    "\n",
    "Different optimizers have different sensitivity to learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different learning rates\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "lr_results = {}\n",
    "\n",
    "# Test Adam with different LRs\n",
    "print(\"Testing Adam with different learning rates...\\n\")\n",
    "for lr in learning_rates:\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    model = SimpleMLP().to(device)\n",
    "    optimizer = AdamOptimizer(model.parameters(), lr=lr)\n",
    "    history = train_with_optimizer(model, optimizer, num_epochs=5, verbose=False)\n",
    "    lr_results[lr] = history\n",
    "    print(f\"  Final test accuracy: {history['test_acc'][-1]:.2f}%\\n\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for lr in learning_rates:\n",
    "    plt.plot(lr_results[lr]['train_loss'], label=f'LR={lr}', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Adam: Learning Rate Sensitivity (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for lr in learning_rates:\n",
    "    plt.plot(lr_results[lr]['test_acc'], label=f'LR={lr}', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Adam: Learning Rate Sensitivity (Accuracy)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Adam is relatively robust to learning rate choice,\")\n",
    "print(\"but LR=0.001 or 0.01 typically works best.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## 6. Gradient Flow Analysis\n",
    "\n",
    "Study how gradients flow through layers in a deeper network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deep-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepMLP(nn.Module):\n",
    "    \"\"\"Deeper network to study gradient flow\"\"\"\n",
    "    def __init__(self, input_size=784, hidden_sizes=[256, 128, 64, 32], num_classes=10):\n",
    "        super(DeepMLP, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.layer_names = [f'Layer{i}' for i in range(len(hidden_sizes) + 1)]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.network(x)\n",
    "\n",
    "model_deep = DeepMLP().to(device)\n",
    "print(model_deep)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model_deep.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient-flow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gradient_flow(model, data_loader, num_batches=10):\n",
    "    \"\"\"\n",
    "    Analyze gradient magnitudes per layer\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Get linear layers\n",
    "    linear_layers = [module for module in model.modules() if isinstance(module, nn.Linear)]\n",
    "    layer_names = [f'Layer {i+1}' for i in range(len(linear_layers))]\n",
    "    \n",
    "    grad_norms = {name: [] for name in layer_names}\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Forward and backward\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Record gradient norms\n",
    "        for name, layer in zip(layer_names, linear_layers):\n",
    "            if layer.weight.grad is not None:\n",
    "                grad_norm = layer.weight.grad.norm().item()\n",
    "                grad_norms[name].append(grad_norm)\n",
    "    \n",
    "    # Average over batches\n",
    "    avg_grad_norms = {name: np.mean(norms) for name, norms in grad_norms.items()}\n",
    "    return avg_grad_norms\n",
    "\n",
    "\n",
    "# Analyze with and without batch norm\n",
    "print(\"Analyzing gradient flow in deep network...\")\n",
    "grad_analysis = analyze_gradient_flow(model_deep, train_loader, num_batches=20)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "layers = list(grad_analysis.keys())\n",
    "norms = list(grad_analysis.values())\n",
    "\n",
    "plt.bar(layers, norms, color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Layer', fontsize=12)\n",
    "plt.ylabel('Average Gradient Norm', fontsize=12)\n",
    "plt.title('Gradient Flow Through Layers', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGradient Norms by Layer:\")\n",
    "for layer, norm in grad_analysis.items():\n",
    "    print(f\"  {layer}: {norm:.6f}\")\n",
    "\n",
    "# Check for vanishing gradients\n",
    "min_norm = min(norms)\n",
    "max_norm = max(norms)\n",
    "ratio = max_norm / min_norm\n",
    "\n",
    "print(f\"\\nGradient magnitude ratio (max/min): {ratio:.2f}\")\n",
    "if ratio > 100:\n",
    "    print(\"⚠️ Warning: Large gradient magnitude differences detected!\")\n",
    "    print(\"   Consider: batch normalization, gradient clipping, or better initialization\")\n",
    "else:\n",
    "    print(\"✓ Gradient flow appears stable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "## 7. Advanced Topics: Loss Landscape Visualization\n",
    "\n",
    "Visualize the loss landscape around the optimal point (2D projection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_landscape_2d(model, data_loader, center_params, \n",
    "                              direction1, direction2, alpha_range=(-1, 1), \n",
    "                              beta_range=(-1, 1), resolution=20):\n",
    "    \"\"\"\n",
    "    Compute 2D slice of loss landscape\n",
    "    \n",
    "    L(alpha, beta) = Loss(center_params + alpha*direction1 + beta*direction2)\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    alphas = np.linspace(alpha_range[0], alpha_range[1], resolution)\n",
    "    betas = np.linspace(beta_range[0], beta_range[1], resolution)\n",
    "    \n",
    "    losses = np.zeros((resolution, resolution))\n",
    "    \n",
    "    # Sample batches for efficiency\n",
    "    sample_data = []\n",
    "    sample_targets = []\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        if batch_idx >= 5:  # Use 5 batches\n",
    "            break\n",
    "        sample_data.append(data)\n",
    "        sample_targets.append(target)\n",
    "    sample_data = torch.cat(sample_data).to(device)\n",
    "    sample_targets = torch.cat(sample_targets).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, alpha in enumerate(alphas):\n",
    "            for j, beta in enumerate(betas):\n",
    "                # Perturb parameters\n",
    "                for p, p_center, d1, d2 in zip(model.parameters(), \n",
    "                                                center_params, direction1, direction2):\n",
    "                    p.data = p_center + alpha * d1 + beta * d2\n",
    "                \n",
    "                # Compute loss\n",
    "                output = model(sample_data)\n",
    "                loss = criterion(output, sample_targets)\n",
    "                losses[i, j] = loss.item()\n",
    "        \n",
    "        # Restore original parameters\n",
    "        for p, p_center in zip(model.parameters(), center_params):\n",
    "            p.data = p_center.clone()\n",
    "    \n",
    "    return alphas, betas, losses\n",
    "\n",
    "\n",
    "# Train a small model first\n",
    "print(\"Training model for loss landscape visualization...\")\n",
    "model_viz = SimpleMLP().to(device)\n",
    "optimizer = AdamOptimizer(model_viz.parameters(), lr=0.01)\n",
    "history = train_with_optimizer(model_viz, optimizer, num_epochs=5, verbose=False)\n",
    "print(f\"Model trained. Test accuracy: {history['test_acc'][-1]:.2f}%\")\n",
    "\n",
    "# Get trained parameters as center\n",
    "center_params = [p.data.clone() for p in model_viz.parameters()]\n",
    "\n",
    "# Generate random directions (normalized)\n",
    "direction1 = [torch.randn_like(p) for p in model_viz.parameters()]\n",
    "direction2 = [torch.randn_like(p) for p in model_viz.parameters()]\n",
    "\n",
    "# Normalize directions\n",
    "norm1 = sum(d.norm()**2 for d in direction1).sqrt()\n",
    "norm2 = sum(d.norm()**2 for d in direction2).sqrt()\n",
    "direction1 = [d / norm1 for d in direction1]\n",
    "direction2 = [d / norm2 for d in direction2]\n",
    "\n",
    "print(\"\\nComputing loss landscape (this may take a minute)...\")\n",
    "alphas, betas, losses = compute_loss_landscape_2d(\n",
    "    model_viz, train_loader, center_params, direction1, direction2,\n",
    "    alpha_range=(-0.5, 0.5), beta_range=(-0.5, 0.5), resolution=15\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(alphas, betas, losses.T, levels=20, cmap='viridis')\n",
    "plt.colorbar(label='Loss')\n",
    "plt.xlabel('Direction 1 (α)')\n",
    "plt.ylabel('Direction 2 (β)')\n",
    "plt.title('Loss Landscape (Contour)', fontweight='bold')\n",
    "plt.plot(0, 0, 'r*', markersize=15, label='Optimum')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "ax = plt.subplot(1, 2, 2, projection='3d')\n",
    "A, B = np.meshgrid(alphas, betas)\n",
    "ax.plot_surface(A, B, losses.T, cmap='viridis', alpha=0.8)\n",
    "ax.set_xlabel('Direction 1 (α)')\n",
    "ax.set_ylabel('Direction 2 (β)')\n",
    "ax.set_zlabel('Loss')\n",
    "ax.set_title('Loss Landscape (3D)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLoss landscape visualized!\")\n",
    "print(f\"Min loss: {losses.min():.4f}\")\n",
    "print(f\"Max loss: {losses.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "### Optimizer Characteristics:\n",
    "\n",
    "1. **SGD (vanilla)**\n",
    "   - ✅ Simple, well-understood\n",
    "   - ❌ Slow convergence\n",
    "   - ❌ Sensitive to learning rate\n",
    "   - ❌ Poor in ravines\n",
    "\n",
    "2. **SGD + Momentum**\n",
    "   - ✅ Faster convergence\n",
    "   - ✅ Dampens oscillations\n",
    "   - ✅ Accelerates in consistent directions\n",
    "   - ⚠️ Can overshoot\n",
    "\n",
    "3. **Nesterov Momentum**\n",
    "   - ✅ Better theoretical convergence rate\n",
    "   - ✅ \"Look-ahead\" prevents overshooting\n",
    "   - ⚠️ Slightly more complex\n",
    "\n",
    "4. **RMSprop**\n",
    "   - ✅ Adaptive per-parameter learning rates\n",
    "   - ✅ Good for non-stationary objectives\n",
    "   - ✅ Handles different scales well\n",
    "   - ⚠️ No momentum\n",
    "\n",
    "5. **Adam** (Most popular in practice)\n",
    "   - ✅ Combines momentum + adaptive LR\n",
    "   - ✅ Works well out-of-the-box\n",
    "   - ✅ Robust to hyperparameter choices\n",
    "   - ⚠️ Can converge to sharp minima\n",
    "   - ⚠️ May need tuning for final accuracy\n",
    "\n",
    "### Practical Guidelines:\n",
    "\n",
    "1. **Default choice**: Adam with lr=0.001\n",
    "2. **For final tuning**: Try SGD + momentum with decaying LR\n",
    "3. **Learning rate**: Most important hyperparameter\n",
    "4. **Gradient clipping**: Use when training RNNs or very deep networks\n",
    "5. **Monitor gradients**: Watch for vanishing/exploding\n",
    "\n",
    "### Mathematical Insights:\n",
    "\n",
    "- **Momentum** ≈ exponentially weighted moving average of gradients\n",
    "- **Adam** ≈ diagonal preconditioning with momentum\n",
    "- **Adaptive methods** adjust per-parameter learning rates\n",
    "- **Batch normalization** smooths loss landscape → easier optimization\n",
    "\n",
    "### When to Use What:\n",
    "\n",
    "- **Quick experiments**: Adam\n",
    "- **Final training**: SGD + momentum with LR schedule\n",
    "- **RNNs**: Adam or RMSprop\n",
    "- **Large batches**: Use higher learning rate with warmup\n",
    "- **Small datasets**: Be careful with adaptive methods (can overfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## 9. Exercises\n",
    "\n",
    "1. **Implement AdamW**: Add weight decay directly to update (not in gradient)\n",
    "2. **Learning rate warmup**: Linearly increase LR for first N steps\n",
    "3. **Gradient clipping**: Implement both norm-based and value-based clipping\n",
    "4. **Second-order methods**: Implement L-BFGS and compare with first-order\n",
    "5. **Hessian analysis**: Compute top eigenvalues of Hessian at optimum\n",
    "6. **Convergence proof**: Prove momentum convergence for quadratic loss\n",
    "7. **Adaptive clipping**: Implement gradient clipping that adapts to gradient history\n",
    "8. **Loss landscape**: Create animated trajectory of optimizer through landscape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
